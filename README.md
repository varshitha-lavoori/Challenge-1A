# ğŸ“„ Connecting the Dots â€” Challenge 1A Solution

## ğŸ‘‹ Overview

This project is my submission for **Round 1A** of the **Adobe India Hackathon 2025**.  
It extracts a **structured outline** from each PDF â€” detecting headings (`H1`, `H2`, `H3`) using text font sizes â€” and saves the result as a valid JSON file for each PDF.

---

## âœ… **Approach**

- ğŸ“š **Library Used:** [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/) (`fitz` in Python)
- ğŸ—‚ï¸ The script loops through all PDFs in `/app/input` automatically.
- ğŸ§© It extracts all text spans and collects **font sizes**.
- ğŸ”¢ The largest font size is treated as `H1`, next as `H2`, next as `H3`.
- ğŸ—‚ï¸ Each heading is saved with `level`, `text`, and `page` number.
- ğŸ“‚ The output JSON file is named `<filename>.json` and stored in `/app/output`.

---

## âœ… **Requirements Satisfied**

âœ”ï¸ Runs **fully offline** â€” no internet needed  
âœ”ï¸ Uses **CPU only** â€” no large models, only PyMuPDF (~20 MB)  
âœ”ï¸ Automatic â€” processes **multiple PDFs** in a loop  
âœ”ï¸ Output format matches **the required schema** (`title` + `outline[]`)  
âœ”ï¸ Compatible with **AMD64 (x86_64)** architecture  
âœ”ï¸ Runs under **10 seconds** for typical 50-page PDFs (PyMuPDF is very fast)  
âœ”ï¸ No file-specific hardcoding or web calls

---

## âœ… **Folder Structure**

```plaintext
connecting-the-dots/
 â”œâ”€â”€ extractor.py      # Main script
 â”œâ”€â”€ Dockerfile        # Container config
 â”œâ”€â”€ README.md         # This file
 â”œâ”€â”€ input/            # Place input PDFs here
 â”œâ”€â”€ output/           # Output JSONs will be written here
```
